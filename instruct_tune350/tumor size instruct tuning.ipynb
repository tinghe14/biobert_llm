{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":190490,"status":"ok","timestamp":1742235209954,"user":{"displayName":"Helen","userId":"05932197665080524617"},"user_tz":240},"id":"7j9uKqx65ZTH"},"outputs":[],"source":["%%capture\n","!pip install datasets\n","!pip install trl\n","!pip install bitsandbytes\n","!pip install vllm"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"yYrqKshS74Qc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742235229719,"user_tz":240,"elapsed":19745,"user":{"displayName":"Helen","userId":"05932197665080524617"}},"outputId":"0aeb1b45-3331-4e7e-990b-9879ad14db0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","os.makedirs('/content/output/Llama-3-8B-Instruct', exist_ok=True)\n","os.makedirs('/content/output/Llama-3-8B-Instruct/NER', exist_ok=True)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O3kWIf8NlYrC","executionInfo":{"status":"ok","timestamp":1742235246753,"user_tz":240,"elapsed":17026,"user":{"displayName":"Helen","userId":"05932197665080524617"}},"outputId":"769d943f-cc50-4826-9cca-dae1ff456b66"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Enter your token (input will not be visible): \n","Add token as git credential? (Y/n) n\n","Token is valid (permission: write).\n","The token `LLama` has been saved to /root/.cache/huggingface/stored_tokens\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful.\n","The current active token is: `LLama`\n"]}],"source":["!huggingface-cli login"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"04S5LnydcFRC"},"outputs":[],"source":["# kiwi paper test data\n","!cp -r /content/drive/MyDrive/KIWI-LLAMA/* /content/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7aXVsa8ncF5z"},"outputs":[],"source":["# temporal tumor size data\n","!cp -r /content/drive/MyDrive/tumor_size_project/temporal_instruct_tune/* /content"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUOmU0woSUqE"},"outputs":[],"source":["# temporal tumor size data - report level\n","!cp -r /content/drive/MyDrive/tumor_size_project/temporal_report_level_instruct_tune/* /content"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3N2N5yrEbktN"},"outputs":[],"source":["# offical train200test100: tumor size data - report level\n","!cp -r /content/drive/MyDrive/tumor_size_project/report_level_instruct_tune/* /content"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sn-36OeX0_ns"},"outputs":[],"source":["# offical train200test100: tumor size data - sent level\n","!cp -r /content/drive/MyDrive/tumor_size_project/instruct_tune/* /content"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"p1zjJZGP_2r_","executionInfo":{"status":"ok","timestamp":1742235528580,"user_tz":240,"elapsed":281824,"user":{"displayName":"Helen","userId":"05932197665080524617"}}},"outputs":[],"source":["# offical train300test100: tumor size data - sent level\n","!cp -r /content/drive/MyDrive/tumor_size_project/instruct_tune300/* /content"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":714},"id":"Tm5Yrhph-wAq","executionInfo":{"status":"ok","timestamp":1742235603035,"user_tz":240,"elapsed":11657,"user":{"displayName":"Helen","userId":"05932197665080524617"}},"outputId":"4cc5bd39-c857-498f-8ab4-e40ed9c52e23"},"outputs":[{"output_type":"stream","name":"stdout","text":["2025-03-17 18:19:55.951246: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1742235595.966259   14388 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1742235595.970345   14388 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-17 18:19:55.985184: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","Could not load bitsandbytes native library: /lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.32' not found (required by /usr/local/lib/python3.11/dist-packages/bitsandbytes/libbitsandbytes_cpu.so)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/cextension.py\", line 85, in <module>\n","    lib = get_native_library()\n","          ^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/cextension.py\", line 72, in get_native_library\n","    dll = ct.cdll.LoadLibrary(str(binary_path))\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/ctypes/__init__.py\", line 454, in LoadLibrary\n","    return self._dlltype(name)\n","           ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/ctypes/__init__.py\", line 376, in __init__\n","    self._handle = _dlopen(self._name, mode)\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n","OSError: /lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.32' not found (required by /usr/local/lib/python3.11/dist-packages/bitsandbytes/libbitsandbytes_cpu.so)\n","CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend\n","Traceback (most recent call last):\n","  File \"/content/train.py\", line 30, in <module>\n","    base_model = AutoModelForCausalLM.from_pretrained(model_name, \n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 564, in from_pretrained\n","    return model_class.from_pretrained(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 3620, in from_pretrained\n","    hf_quantizer.validate_environment(\n","  File \"/usr/local/lib/python3.11/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py\", line 83, in validate_environment\n","    validate_bnb_backend_availability(raise_exception=True)\n","  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/bitsandbytes.py\", line 559, in validate_bnb_backend_availability\n","    return _validate_bnb_cuda_backend_availability(raise_exception)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/bitsandbytes.py\", line 537, in _validate_bnb_cuda_backend_availability\n","    raise RuntimeError(log_msg)\n","RuntimeError: CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend\n"]}],"source":["!python train.py # 4685line, 38 min, total ~50 min for mtsample\n","#14336line, 3x, estimated 2hr for train200test100\n","#6 reports, 5 min\n","#200 reports, 12 min\n","from google.colab import output\n","output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"DcrSxxoOnRLV","executionInfo":{"status":"ok","timestamp":1742235614768,"user_tz":240,"elapsed":11731,"user":{"displayName":"Helen","userId":"05932197665080524617"}},"outputId":"e84993bb-5904-4f83-a6c1-fb21d8c05f21"},"outputs":[{"output_type":"stream","name":"stdout","text":["2025-03-17 18:20:08.358108: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1742235608.372885   14464 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1742235608.377104   14464 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-17 18:20:08.391427: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","INFO 03-17 18:20:11 __init__.py:211] No platform detected, vLLM is running on UnspecifiedPlatform\n","Traceback (most recent call last):\n","  File \"/content/inference.py\", line 21, in <module>\n","    llm = LLM(model=f\"{model_dir}\", tensor_parallel_size=len(device_map))  # Create an LLM.\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/vllm/utils.py\", line 1022, in inner\n","    return fn(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/llm.py\", line 242, in __init__\n","    self.llm_engine = self.engine_class.from_engine_args(\n","                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/llm_engine.py\", line 486, in from_engine_args\n","    engine_config = engine_args.create_engine_config(usage_context)\n","                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/arg_utils.py\", line 1126, in create_engine_config\n","    device_config = DeviceConfig(device=self.device)\n","                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/vllm/config.py\", line 1660, in __init__\n","    raise RuntimeError(\"Failed to infer device type\")\n","RuntimeError: Failed to infer device type\n"]}],"source":["!python inference.py # test 100 in report level, 14 min\n","from google.colab import output\n","output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u3ur1efwVJU7"},"outputs":[],"source":["# kiwi paper test data\n","!cp -r /content/output/* /content/drive/MyDrive/KIWI-LLAMA/output/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ObUqnxlWcY7F"},"outputs":[],"source":["# temporal tumor size data\n","!cp -r /content/output/* /content/drive/MyDrive/tumor_size_project/temporal_instruct_tune/output/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9dhNCbpSSj4y"},"outputs":[],"source":["# temporal tumor size data - report level\n","!cp -r /content/output/* /content/drive/MyDrive/tumor_size_project/temporal_report_level_instruct_tune/output/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w0anOCGSbzc8"},"outputs":[],"source":["# offical train200test100: tumor size data - report level\n","!cp -r /content/output/* /content/drive/MyDrive/tumor_size_project/report_level_instruct_tune/output/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vd8Mu-fb1M7r"},"outputs":[],"source":["# offical train200test100: tumor size data - sent level\n","!cp -r /content/output/* /content/drive/MyDrive/tumor_size_project/instruct_tune/output/"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"W7DAMIdS_-m8","executionInfo":{"status":"ok","timestamp":1742235614910,"user_tz":240,"elapsed":138,"user":{"displayName":"Helen","userId":"05932197665080524617"}}},"outputs":[],"source":["# offical train300test100: tumor size data - sent level\n","!cp -r /content/output/* /content/drive/MyDrive/tumor_size_project/instruct_tune300/output/"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyMtBP6U5vLRNQKOsSt45svT"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}